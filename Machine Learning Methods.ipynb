{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import DataCleaner\n",
    "\n",
    "def KNN(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #KNN方法来分类\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "    #使用训练集训练模型\n",
    "    print('Starting KNN training process....')\n",
    "    knn.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(knn.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(knn.score(testData_X,testData_Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def seperateData(data,label,percentage = 0.25):\n",
    "    trainData = data.tolist()\n",
    "    trainLabel = label.tolist()\n",
    "    testData_X = []\n",
    "    testData_Y = []\n",
    "    #训练集和测试集3:1，随机抽取\n",
    "    testLen = int(len(data)*percentage)\n",
    "    for i in range(0,testLen):               \n",
    "        listIndex = random.randint(0,len(trainData)-1)\n",
    "        testData_X.append(trainData[listIndex])\n",
    "        trainData.remove(trainData[listIndex])\n",
    "        testData_Y.append(trainLabel[listIndex])\n",
    "        trainLabel.remove(trainLabel[listIndex])\n",
    "    trainData_X = trainData\n",
    "    trainData_Y = trainLabel\n",
    "    return trainData_X,trainData_Y,testData_X,testData_Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "def DecisionTree(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #决策树方法\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "    print('Starting DecisionTree training process....')\n",
    "    dt.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(dt.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(dt.score(testData_X,testData_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def logisticRegression(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #逻辑回归\n",
    "    lr = LogisticRegression()\n",
    "    print('Starting LogisticRegression training process....')\n",
    "    lr.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(lr.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(lr.score(testData_X,testData_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def SVM(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #SVM\n",
    "    svm1 = svm.SVC(C=1, kernel='linear', gamma=10, decision_function_shape='ovo')\n",
    "    print('Starting svm training process....')\n",
    "    svm1.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(svm1.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(svm1.score(testData_X,testData_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def bayesMultinomia(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #Multinomia朴素贝叶斯\n",
    "    bayes = MultinomialNB()\n",
    "    print('Starting GaussBayes bayes training process....')\n",
    "    bayes.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(bayes.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(bayes.score(testData_X,testData_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def bayesGauss(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #高斯朴素贝叶斯\n",
    "    bayes = GaussianNB()\n",
    "    print('Starting  Multinomial training process....')\n",
    "    bayes.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(bayes.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(bayes.score(testData_X,testData_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "def bayesBernoulli(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #伯努利朴素贝叶斯\n",
    "    bayes = BernoulliNB()\n",
    "    print('Starting BernoulliNB training process....')\n",
    "    bayes.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(bayes.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(bayes.score(testData_X,testData_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "def RandomForest(trainData_X,trainData_Y,testData_X,testData_Y):\n",
    "    #随机森林\n",
    "    n_features=len(trainData_X[0])\n",
    "    rf = RandomForestClassifier(n_estimators=10,max_features=n_features, max_depth=None,min_samples_split=2, bootstrap=True)\n",
    "    print('Starting RandomForest training process....')\n",
    "    rf.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(rf.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(rf.score(testData_X,testData_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN training process....\n",
      "Precison of training data: 0.7137850467289719\n",
      "Precision of testing data: 0.5614035087719298\n"
     ]
    }
   ],
   "source": [
    "data,label = DataCleaner.loadData()\n",
    "trainData_X,trainData_Y,testData_X,testData_Y = seperateData(data,label)\n",
    "KNN(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DecisionTree training process....\n",
      "Precison of training data: 0.8107476635514018\n",
      "Precision of testing data: 0.5298245614035088\n"
     ]
    }
   ],
   "source": [
    "DecisionTree(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LogisticRegression training process....\n",
      "Precison of training data: 0.7605140186915887\n",
      "Precision of testing data: 0.5824561403508772\n"
     ]
    }
   ],
   "source": [
    "logisticRegression(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting svm training process....\n",
      "Precison of training data: 0.8107476635514018\n",
      "Precision of testing data: 0.5719298245614035\n"
     ]
    }
   ],
   "source": [
    "SVM(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting svm training process....\n",
      "Precison of training data: 0.5759345794392523\n",
      "Precision of testing data: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "bayesGauss(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GaussBayes bayes training process....\n",
      "Precison of training data: 0.5957943925233645\n",
      "Precision of testing data: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "bayesMultinomia(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BernoulliNB training process....\n",
      "Precison of training data: 0.5373831775700935\n",
      "Precision of testing data: 0.4245614035087719\n"
     ]
    }
   ],
   "source": [
    "bayesBernoulli(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RandomForest training process....\n",
      "Precison of training data: 0.8014018691588785\n",
      "Precision of testing data: 0.5298245614035088\n"
     ]
    }
   ],
   "source": [
    "RandomForest(trainData_X,trainData_Y,testData_X,testData_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
