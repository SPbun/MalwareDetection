#!/usr/bin/env python
# coding: utf-8

# In[31]:


from sklearn.neighbors import KNeighborsClassifier
import DataCleaner

def KNN(trainData_X,trainData_Y,testData_X,testData_Y):
    #KNN方法来分类
    knn = KNeighborsClassifier(n_neighbors = 3)
    #使用训练集训练模型
    print('Starting KNN training process....')
    knn.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(knn.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(knn.score(testData_X,testData_Y)))


# In[29]:


import random
def seperateData(data,label,percentage = 0.25):
    trainData = data.tolist()
    trainLabel = label.tolist()
    testData_X = []
    testData_Y = []
    #训练集和测试集3:1，随机抽取
    testLen = int(len(data)*percentage)
    for i in range(0,testLen):               
        listIndex = random.randint(0,len(trainData)-1)
        testData_X.append(trainData[listIndex])
        trainData.remove(trainData[listIndex])
        testData_Y.append(trainLabel[listIndex])
        trainLabel.remove(trainLabel[listIndex])
    trainData_X = trainData
    trainData_Y = trainLabel
    return trainData_X,trainData_Y,testData_X,testData_Y
    


# In[33]:


from sklearn import tree
def DecisionTree(trainData_X,trainData_Y,testData_X,testData_Y):
    #决策树方法
    dt = tree.DecisionTreeClassifier()
    print('Starting DecisionTree training process....')
    dt.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(dt.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(dt.score(testData_X,testData_Y)))


# In[37]:


from sklearn.linear_model import LogisticRegression
def logisticRegression(trainData_X,trainData_Y,testData_X,testData_Y):
    #逻辑回归
    lr = LogisticRegression()
    print('Starting LogisticRegression training process....')
    lr.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(lr.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(lr.score(testData_X,testData_Y)))


# In[64]:


from sklearn import svm
def SVM(trainData_X,trainData_Y,testData_X,testData_Y):
    #SVM
    svm1 = svm.SVC(C=1, kernel='linear', gamma=10, decision_function_shape='ovo')
    print('Starting svm training process....')
    svm1.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(svm1.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(svm1.score(testData_X,testData_Y)))


# In[74]:


from sklearn.naive_bayes import MultinomialNB
def bayesMultinomia(trainData_X,trainData_Y,testData_X,testData_Y):
    #Multinomia朴素贝叶斯
    bayes = MultinomialNB()
    print('Starting GaussBayes bayes training process....')
    bayes.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(bayes.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(bayes.score(testData_X,testData_Y)))


# In[75]:


from sklearn.naive_bayes import GaussianNB
def bayesGauss(trainData_X,trainData_Y,testData_X,testData_Y):
    #高斯朴素贝叶斯
    bayes = GaussianNB()
    print('Starting  Multinomial training process....')
    bayes.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(bayes.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(bayes.score(testData_X,testData_Y)))


# In[76]:


from sklearn.naive_bayes import BernoulliNB
def bayesBernoulli(trainData_X,trainData_Y,testData_X,testData_Y):
    #伯努利朴素贝叶斯
    bayes = BernoulliNB()
    print('Starting BernoulliNB training process....')
    bayes.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(bayes.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(bayes.score(testData_X,testData_Y)))


# In[87]:


from sklearn.ensemble import RandomForestClassifier
import math
def RandomForest(trainData_X,trainData_Y,testData_X,testData_Y):
    #随机森林
    n_features=len(trainData_X[0])
    rf = RandomForestClassifier(n_estimators=10,max_features=n_features, max_depth=None,min_samples_split=2, bootstrap=True)
    print('Starting RandomForest training process....')
    rf.fit(trainData_X,trainData_Y)
    print('Precison of training data: ' + str(rf.score(trainData_X,trainData_Y)))
    print('Precision of testing data: ' + str(rf.score(testData_X,testData_Y)))


# In[52]:


data,label = DataCleaner.loadData()
trainData_X,trainData_Y,testData_X,testData_Y = seperateData(data,label)
KNN(trainData_X,trainData_Y,testData_X,testData_Y)


# In[53]:


DecisionTree(trainData_X,trainData_Y,testData_X,testData_Y)


# In[54]:


logisticRegression(trainData_X,trainData_Y,testData_X,testData_Y)


# In[66]:


SVM(trainData_X,trainData_Y,testData_X,testData_Y)


# In[70]:


bayesGauss(trainData_X,trainData_Y,testData_X,testData_Y)


# In[77]:


bayesMultinomia(trainData_X,trainData_Y,testData_X,testData_Y)


# In[78]:


bayesBernoulli(trainData_X,trainData_Y,testData_X,testData_Y)


# In[88]:


RandomForest(trainData_X,trainData_Y,testData_X,testData_Y)


# In[ ]:




